# olist-sales-ft

TODO : setup data warehouse with airflow each time the pipeline is run

1. config dockerfile for webserver and scheduler according to your ship architecture
2. setup dw
2. setup spark-conn in airflow
3. upload data to minio
4. download jars 
link to mysql connector jar: https://repo.maven.apache.org/maven2/com/mysql/mysql-connector-j/8.4.0/mysql-connector-j-8.4.0.jar
link to hadoop-aws jar: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar
link to aws-java-sdk jar: https://repo.maven.apache.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar